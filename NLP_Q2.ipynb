{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "QMaZ68bW-Nrd"
      ],
      "mount_file_id": "1uZtan-PhMG0bvt77qHlvRqAGnBDefOfX",
      "authorship_tag": "ABX9TyON7yzt/6KfIwoGkpkKxMFc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ManeeshGuptaNvss/ML_Projects/blob/main/NLP_Q2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tokenization"
      ],
      "metadata": {
        "id": "XRvVB-rb-COT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 189,
      "metadata": {
        "id": "dnqzE0LYWo7t"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "def tokenize(text):\n",
        "\n",
        "    text = text.lower() \n",
        "\n",
        "    # decontraction \n",
        "    # regex_dict ={\n",
        "    #     \"won\\'t\":\"will not\",\n",
        "    #     \"can\\'t\": \"can not\",\n",
        "    #     \"n\\'t\": \" not\",\n",
        "    #     \"\\'re\": \" are\", \n",
        "    #     \"\\'s\": \" is\", \n",
        "    #     \"\\'d\": \" would\", \n",
        "    #     \"\\'ll\": \" will\", \n",
        "    #     \"\\'t\": \" not\", \n",
        "    #     \"\\'ve\": \" have\", \n",
        "    #     \"\\'m\": \" am\" \n",
        "    # }\n",
        "    \n",
        "    # for key,value in regex_dict.items():\n",
        "    #   text = re.sub(key,value,text)\n",
        "    \n",
        "    #  removing all commas in huge numbers\n",
        "    regex_to_modify_numbers = '(?<=\\d),(?=\\d)'\n",
        "\n",
        "    pattern1 = re.compile(regex_to_modify_numbers)\n",
        "    text = re.sub(pattern1, '', text) \n",
        "\n",
        "    # Regular expression pattern to match URLs\n",
        "    regex1 = '(?:(?:https?|ftp):\\/\\/)?[\\w/\\-?=%.]+\\.[\\w/\\-&?=%.]+'\n",
        "    regex2 = '(http|ftp|https|www)://([\\w_-]+(?:(?:\\.[\\w_-]+)+))([\\w.,@?^=%&:/~+#-]*[\\w@?^=%&/~+#-])?'\n",
        "\n",
        "    regex_for_email = '[\\w.+-]+@[\\w-]+\\.[\\w.-]+'\n",
        "    email_pattern = re.compile(regex_for_email)\n",
        "    \n",
        "    # Replace emails with <EMAIL> placeholder\n",
        "    text = re.sub(email_pattern,'<EMAIL>',text)\n",
        "\n",
        "    #  working best\n",
        "    regex_for_website = '([\\w+]+\\:\\/\\/)?([\\w\\d-]+\\.)*[\\w-]+[\\.\\:]\\w+([\\/\\?\\=\\&\\#.]?[\\w-]+)*\\/?'\n",
        "    url_pattern = re.compile(regex_for_website)\n",
        "\n",
        "    # Replace URLs with <URL> placeholder\n",
        "    text = re.sub(url_pattern, \"<URL>\", text)\n",
        "\n",
        "    # Regular expression pattern to match hashtags\n",
        "    hashtag_pattern = re.compile(r'#\\w+')\n",
        "\n",
        "    # Replace hashtags with <HASHTAG> placeholder\n",
        "    text = re.sub(hashtag_pattern, '<HASHTAG>', text)\n",
        "\n",
        "    # Regular expression pattern to match mentions\n",
        "    mention_pattern = re.compile(r'@\\w+')\n",
        "\n",
        "    # Replace mentions with <MENTION> placeholder\n",
        "    text = re.sub(mention_pattern, '<MENTION>', text)\n",
        "\n",
        "    # removing unwanted special characters (not punctuations)\n",
        "    # text = re.sub(r'[*|^|~|\\/|+|_|$]',r' ',text)\n",
        "    text = re.sub(r'(\\W)\\1+', r'\\1', text)\n",
        "    # text = re.sub(r'[^a-zA-Z0-9<>\\n]',r'\\s\\1\\s',text)\n",
        "    # print(text)\n",
        "    # Tokenize text into words and punctuation\n",
        "    # r'\\b\\w+\\b|[^\\w\\s]+'\n",
        "    pattern = r'(?:[\\w]+|<HASHTAG>|<MENTION>|<URL>|<NUMBER>|<EMAIL>|<s>|<\\s>|[.?!,;:_\\(\\)\\[\\]/\\-\\\"\\']+)'\n",
        "    # words = re.findall(r'\\b\\w+\\b|[^\\w\\s]+', text)\n",
        "    words = re.findall(pattern,text)\n",
        "    return words\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# N gram Generation"
      ],
      "metadata": {
        "id": "eWQ-ENxZ-JI6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def get_ngrams(tokens):\n",
        "  unigram,bigram,trigram,fourgram=dict(),dict(),dict(),dict()\n",
        "  size = len(tokens)\n",
        "  for i in range(size):\n",
        "    \n",
        "    unigram[tokens[i]] = unigram.get(tokens[i],0)+1\n",
        "    \n",
        "    if i+1<size:\n",
        "        if bigram.get(tokens[i],0) == 0:\n",
        "          bigram[tokens[i]] = dict()\n",
        "        bigram[tokens[i]][tokens[i+1]] = bigram[tokens[i]].get(tokens[i+1],0)+1\n",
        "        \n",
        "    if i+2<size:\n",
        "        if trigram.get(tokens[i]+' '+tokens[i+1],0) == 0:\n",
        "            trigram[tokens[i]+' '+tokens[i+1]] = dict()\n",
        "        trigram[tokens[i]+' '+tokens[i+1]][tokens[i+2]] = trigram[tokens[i]+' '+tokens[i+1]].get(tokens[i+2],0) + 1\n",
        "\n",
        "    if i+3<size:\n",
        "        if fourgram.get(tokens[i]+' '+tokens[i+1]+' '+tokens[i+2],0) == 0:\n",
        "            fourgram[tokens[i]+' '+tokens[i+1]+' '+tokens[i+2]] = dict()\n",
        "        fourgram[tokens[i]+' '+tokens[i+1]+' '+tokens[i+2]][tokens[i+3]] = fourgram[tokens[i]+' '+tokens[i+1]+' '+tokens[i+2]].get(tokens[i+3],0) + 1\n",
        "  \n",
        "  return unigram, bigram, trigram, fourgram\n",
        "        "
      ],
      "metadata": {
        "id": "74U4NYwcqNMh"
      },
      "execution_count": 190,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Witten Bell Smoothing"
      ],
      "metadata": {
        "id": "QMaZ68bW-Nrd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_unigram_wb_probability(unigram,unigram_header):\n",
        "  res = 0\n",
        "  den = 0\n",
        "  lambda1 = 0\n",
        "  unigram_word_count = unigram.get(unigram_header,0)\n",
        "\n",
        "  total_unigrams = 0\n",
        "  for key,value in unigram.items():\n",
        "    total_unigrams+=value\n",
        "  lambda1 = 1 - (len(unigram)/(len(unigram)+total_unigrams))\n",
        "  res = ((lambda1 * unigram_word_count) / total_unigrams) + (1 - lambda1) / len(unigram)\n",
        "\n",
        "  return res\n"
      ],
      "metadata": {
        "id": "ZIzbDAne4RCj"
      },
      "execution_count": 191,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_bigram_wb_probability(unigram, bigram, bigram_context,bigram_header):\n",
        "  res = 0\n",
        "  den = 0\n",
        "  lambda1 = 0\n",
        "  first = 0\n",
        "  if bigram.get(bigram_context) == 0:\n",
        "    for key,value in bigram[bigram_context].items():\n",
        "      den +=value\n",
        "    num = bigram[bigram_context].get(bigram_header,0)\n",
        "\n",
        "    if den == 0:\n",
        "      den = 1 \n",
        "    \n",
        "    first = num / den\n",
        "\n",
        "    given_bigram_types = len(bigram[bigram_context])\n",
        "    given_bigram_T = den\n",
        "\n",
        "    #  1 - lambda1 = N / ( N + T )\n",
        "    lambda1 = 1 - ( (given_bigram_types)/(given_bigram_types + given_bigram_T) )\n",
        "  \n",
        "  # unigram_context = trigram_context.split()[-1]\n",
        "  unigram_header = bigram_header\n",
        "  res = lambda1 * first + (1-lambda1) * (calc_unigram_wb_probability(unigram,unigram_header))\n",
        "  return res"
      ],
      "metadata": {
        "id": "aKTPGAXX3Kc-"
      },
      "execution_count": 192,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_trigram_wb_probability(unigram,bigram,trigram,trigram_context,trigram_header):\n",
        "  res=0\n",
        "  den=0\n",
        "  lambda1=0\n",
        "  first = 0\n",
        "  # print(trigram_context)\n",
        "  if trigram.get(trigram_context,0) != 0: \n",
        "    for key,value in trigram[trigram_context].items():\n",
        "      den +=value\n",
        "    num = trigram[trigram_context].get(trigram_header,0)\n",
        "\n",
        "    if den == 0:\n",
        "      den = 1\n",
        "    first = num / den\n",
        "\n",
        "    given_trigram_types = len(trigram[trigram_context])\n",
        "    given_trigram_T = den\n",
        "\n",
        "    #  1 - lambda1 = N / ( N + T )\n",
        "    lambda1 = 1 - ( (given_trigram_types)/(given_trigram_types + given_trigram_T) )\n",
        "  \n",
        "  bigram_context = ' '.join(trigram_context.split()[-1:])\n",
        "  bigram_header = trigram_header\n",
        "  res = lambda1 * first + (1-lambda1) * (calc_bigram_wb_probability(unigram,bigram,bigram_context,bigram_header))\n",
        "  return res"
      ],
      "metadata": {
        "id": "uBhyprst0HuW"
      },
      "execution_count": 193,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_fourgram_wb_probability(unigram,bigram,trigram,fourgram,fourgram_context,fourgram_header):\n",
        "  res=0\n",
        "  den=0\n",
        "  lambda1 = 0\n",
        "  first = 0\n",
        "  if fourgram.get(fourgram_context,0) != 0:\n",
        "    for key,value in fourgram[fourgram_context].items():\n",
        "      den +=value\n",
        "    num = fourgram[fourgram_context].get(fourgram_header,0)\n",
        "\n",
        "    if den == 0:\n",
        "      den = 1\n",
        "    first = num / den\n",
        "\n",
        "    given_fourgram_types = len(fourgram[fourgram_context])\n",
        "    given_fourgram_T = den\n",
        "\n",
        "    #  1 - lambda1 = N / ( N + T )\n",
        "    lambda1 = 1 - ( (given_fourgram_types)/(given_fourgram_types + given_fourgram_T) )\n",
        "\n",
        "  trigram_context = ' '.join(fourgram_context.split()[-2:])\n",
        "  trigram_header = fourgram_header\n",
        "  res = lambda1 * first + (1-lambda1) * (calc_trigram_wb_probability(unigram,bigram,trigram,trigram_context,trigram_header))\n",
        "  return res\n"
      ],
      "metadata": {
        "id": "hJxmBOb8utNb"
      },
      "execution_count": 194,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# K N Smoothing"
      ],
      "metadata": {
        "id": "W2TlQdw_De4L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_unigram_kn_prob(unigram,bigram,trigram,fourgram,d,fourgram_context,fourgram_header):\n",
        "  num = 0\n",
        "  den = 0\n",
        "  first = 0\n",
        "  lambda1 = 0\n",
        "  N = 0\n",
        "  T = 0\n",
        "\n",
        "  unigram_context = fourgram_context.split()[-1]\n",
        "  for key, header_dict in bigram.items():\n",
        "    for header, val in header_dict.items():\n",
        "      if header == unigram_context:\n",
        "        num+=val\n",
        "    den += len(header_dict)\n",
        "  \n",
        "  if den == 0:\n",
        "    den = 1\n",
        "  for key,val in unigram.items():\n",
        "    T += val\n",
        "  if T == 0:\n",
        "    T = 1\n",
        "  N = len(unigram)\n",
        "  lambda1 = (d * N) / T\n",
        "  if lambda1 == 0:\n",
        "    lambda1 = 1\n",
        "  res = max(num-d,0)/den + (lambda1 /len(unigram))\n",
        "  return res\n"
      ],
      "metadata": {
        "id": "VH5DIIMKtNSd"
      },
      "execution_count": 195,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_bigram_kn_prob(unigram,bigram,trigram,fourgram,d,fourgram_context,fourgram_header):\n",
        "  num = 0\n",
        "  den = 0\n",
        "  first = 0\n",
        "  lambda1 = 0\n",
        "  N = 0\n",
        "  T = 0\n",
        "  # finding *cd\n",
        "  bigram_context = fourgram_context.split()[-2]\n",
        "  bigram_header = fourgram_context.split()[-1]\n",
        "\n",
        "  # finding **c\n",
        "  bigram_header2 = fourgram_context.split()[-2]\n",
        "  for key, header_dict in trigram.items():\n",
        "    last_1_part = key.split()[-1]\n",
        "    for header, val in header_dict.items():\n",
        "      if last_1_part == bigram_context and header == bigram_header:\n",
        "        num += val\n",
        "      if header == bigram_header2:\n",
        "        den += val\n",
        "  \n",
        "  if den == 0:\n",
        "    den = 1\n",
        "  # [c] -> cd, ce, cf\n",
        "  bigram_context2 = fourgram_context.split()[-1]\n",
        "  if bigram.get(bigram_context2,0):\n",
        "    for key,val in bigram[bigram_context2].items():\n",
        "      T += val\n",
        "    N = len(bigram[bigram_context2])\n",
        "  if T == 0: \n",
        "    T = 1\n",
        "  lambda1 = (d * N) / T\n",
        "  if lambda1 == 0:\n",
        "    lambda1 = 1\n",
        "  res = max(num-d,0)/den + lambda1 * calc_unigram_kn_prob(unigram,bigram,trigram,fourgram,d,fourgram_context,fourgram_header)\n",
        "  return res"
      ],
      "metadata": {
        "id": "mOON542DZVTr"
      },
      "execution_count": 196,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_trigram_kn_prob(unigram,bigram,trigram,fourgram,d,fourgram_context,fourgram_header):\n",
        "  num=0\n",
        "  den=0\n",
        "  first = 0\n",
        "  lambda1 = 0\n",
        "  N = 0\n",
        "  T = 0\n",
        "  # finding *bcd\n",
        "  trigram_context = \" \".join(fourgram_context.split()[-2:])\n",
        "  trigram_header = fourgram_header\n",
        " \n",
        "  #finding **bc\n",
        "  trigram_context2 = fourgram_context.split()[-2]\n",
        "  trigram_header2 = fourgram_context.split()[-1]\n",
        "  \n",
        "  for key, header_dict in fourgram.items():\n",
        "      last_2_parts = \" \".join(key.split()[-2:])\n",
        "      if last_2_parts == trigram_context:\n",
        "        for header, val in header_dict.items():\n",
        "          if header == trigram_header:\n",
        "            num += val\n",
        "      last_1_part = key.split()[-1]\n",
        "      if last_1_part == trigram_context2:\n",
        "        for header, val in header_dict.items():\n",
        "          if header == trigram_header2:\n",
        "            den+=val\n",
        "  if den == 0:\n",
        "    den = 1\n",
        "  \n",
        "  # [bc]->bcd, bce, bcf\n",
        "  trigram_context3 = \" \".join(fourgram_context.split()[-2:])\n",
        "  if(trigram.get(trigram_context3,0)):\n",
        "    for key, val in trigram[trigram_context3].items():\n",
        "      T += val\n",
        "    N = len(trigram[trigram_context3])\n",
        "\n",
        "  if T == 0:\n",
        "    T = 1\n",
        "  lambda1 = (d * N) / T\n",
        "  if lambda1 == 0:\n",
        "    lambda1 = 1\n",
        "\n",
        "  res = max(num-d,0)/den + lambda1 * calc_bigram_kn_prob(unigram,bigram,trigram,fourgram,d,fourgram_context,fourgram_header)\n",
        "  return res\n",
        "      "
      ],
      "metadata": {
        "id": "zvtpi6N9LQob"
      },
      "execution_count": 197,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_fourgram_kn_prob(unigram, bigram, trigram, fourgram,d,fourgram_context,fourgram_header):\n",
        "  num=0\n",
        "  den=0\n",
        "  first = 0\n",
        "  lambda1 = 0\n",
        "  N = 0\n",
        "  T = 0\n",
        "  if fourgram.get(fourgram_context,0):\n",
        "    num = fourgram[fourgram_context].get(fourgram_header,0)\n",
        "    for key, val in fourgram[fourgram_context].items():\n",
        "      den+=val\n",
        "    N = len(fourgram[fourgram_context])\n",
        "    \n",
        "  if den == 0:\n",
        "    den = 1 \n",
        "  T = den\n",
        "  lambda1 = (d*N)/T\n",
        "  first = max(num-d,0) / den \n",
        "  if lambda1 == 0:\n",
        "    lambda1 = 1 \n",
        "  # print('4: ',first,lambda1)\n",
        "  res = first + lambda1 * calc_trigram_kn_prob(unigram,bigram,trigram,fourgram,d,fourgram_context,fourgram_header)\n",
        "  return res"
      ],
      "metadata": {
        "id": "V2ThsOweF3GY"
      },
      "execution_count": 198,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Main"
      ],
      "metadata": {
        "id": "BtR2ZTmFFrBs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_ngrams2(corpus,n):\n",
        "    token = tokenize(corpus)\n",
        "    ngrams = zip(*[token[i:] for i in range(n)])\n",
        "    ngram_list = [\" \".join(gram) for gram in ngrams]\n",
        "    return ngram_list,len(token)"
      ],
      "metadata": {
        "id": "ux8FJhyWjXt1"
      },
      "execution_count": 200,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "def splitdata(sentence_list,n):\n",
        "  test_indices = np.random.choice(len(sentence_list), size=n, replace=False)\n",
        "  mask = np.ones(len(sentence_list), bool)\n",
        "  mask[test_indices] = False\n",
        "  train_set = list(np.array(sentence_list)[mask])\n",
        "  test_set = list(np.array(sentence_list)[~mask])\n",
        "  return train_set, test_set"
      ],
      "metadata": {
        "id": "-Wtwu3qBpj26"
      },
      "execution_count": 202,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_perplexity_kn(unigram,bigram,trigram,fourgram,d,sentence):\n",
        "  sentence = '<s>'+' '+'<s>'+' '+'<s>'+' '+sentence+' '+'<\\s>'+' '+'<\\s>'+' '+'<\\s>'\n",
        "  input_fourgram,n = get_ngrams2(sentence,4)\n",
        "  res=1\n",
        "  for gram in input_fourgram:\n",
        "    context = \" \".join(gram.split()[:-1])\n",
        "    header = gram.split()[-1]\n",
        "    res*=calc_fourgram_kn_prob(unigram,bigram,trigram,fourgram,d,context,header)\n",
        "  res2 = pow(1/res,1/n)\n",
        "  return res2"
      ],
      "metadata": {
        "id": "4qUngsAcTqUW"
      },
      "execution_count": 203,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_perplexity(unigram,bigram,trigram,fourgram,sentence):\n",
        "  sentence = '<s>'+' '+'<s>'+' '+'<s>'+' '+sentence+' '+'<\\s>'+' '+'<\\s>'+' '+'<\\s>'\n",
        "  input_fourgram,n = get_ngrams2(sentence,4)\n",
        "  res=1\n",
        "  for gram in input_fourgram:\n",
        "    context = \" \".join(gram.split()[:-1])\n",
        "    header = gram.split()[-1]\n",
        "    res*=calc_fourgram_wb_probability(unigram,bigram,trigram,fourgram,context,header)\n",
        "  res2 = pow(1/res,1/n)\n",
        "  return res2\n",
        "  \n",
        "\n"
      ],
      "metadata": {
        "id": "sw72PIoTd6Oy"
      },
      "execution_count": 204,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__==\"__main__\":\n",
        "    filename = '/content/drive/MyDrive/IIIT Hyderabad/Semester 4/Intro. To NLP/Assignment 1/hello.txt'\n",
        "    filename = '/content/drive/MyDrive/IIIT Hyderabad/Semester 4/Intro. To NLP/Assignment 1/Pride and Prejudice - Jane Austen.txt'\n",
        "    \n",
        "    with open(filename,'r') as f:\n",
        "\n",
        "        string = f.read()\n",
        "        sentencelist=string.split('\\n')\n",
        "        train_set,test_set = splitdata(sentencelist,1000)\n",
        "        tokens=[]\n",
        "        for string in train_set:\n",
        "          tokens.extend(tokenize(string))\n",
        "        unigram, bigram, trigram, fourgram = get_ngrams(tokens)\n",
        "        fourgram_context = 'maneesh is a'\n",
        "        fourgram_header = 'girl'\n",
        "        \n",
        "        d=0.75\n",
        "        print(calc_fourgram_wb_probability(unigram,bigram,trigram,fourgram,fourgram_context,fourgram_header))\n",
        "        print(calc_fourgram_kn_prob(unigram, bigram, trigram, fourgram,d,fourgram_context,fourgram_header) )\n",
        "        \n",
        "        perplexity = 0\n",
        "        for sentence in test_set:\n",
        "            perplexity += calc_perplexity(unigram,bigram,trigram,fourgram,sentence)\n",
        "            # print(perplexity)\n",
        "        print(\"WB: \",perplexity/1000)\n",
        "\n",
        "        perplexity2 = 0\n",
        "        N = 10\n",
        "        for sentence in test_set[:N]:\n",
        "            perplexity2 += calc_perplexity_kn(unigram,bigram,trigram,fourgram,0.75,sentence)\n",
        "        print(\"KN: \",perplexity2/N)\n",
        "      "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R2-StrCHa0ap",
        "outputId": "fddc4d27-3869-4e14-f852-a9466d531ba6"
      },
      "execution_count": 205,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.00010962837356947829\n",
            "0.047579554261088314\n",
            "WB:  119.00257716534502\n",
            "KN:  73.72396911231135\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Useless"
      ],
      "metadata": {
        "id": "k8by76Fa-glE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "string = \"My name is Maneesh Gupta\"\n",
        "trigram_context = ' '.join(string.split()[-3:])\n",
        "print(trigram_context)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YNV89BCY0zB8",
        "outputId": "8918de8c-1be1-4f95-9e24-e5c51c7feada"
      },
      "execution_count": 206,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "is Maneesh Gupta\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "l1 = zip(*[[1,2,3],[2,3,4],[3,4,5]])\n",
        "print(*l1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MINQ07N4e4yG",
        "outputId": "81089dcb-4e13-4721-8ac1-0fae5ede6879"
      },
      "execution_count": 207,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1, 2, 3) (2, 3, 4) (3, 4, 5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "```\n",
        "is a\n",
        "1.2834039189034834e-05\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "Hs3GpcmJ2I-y"
      }
    }
  ]
}